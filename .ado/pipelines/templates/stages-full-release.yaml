parameters:
  - name: environment
    type: string
  - name: destroyOldEnvironment
    type: boolean
    default: true
  - name: trafficSwitchSteps # in which steps (weights) the gradual traffic switch in Front Door should happen
    type: object
    default:
    - 10
    - 50
    - 100

stages:

- stage: deployglobalinfrastructure
  displayName: 'Deploy Global Infrastructure' # Deploy Global Azure Infrastructure
  jobs:

  - deployment: deployterraformglobalresources
    displayName: 'Deploy Terraform Global Resources'
    timeoutInMinutes: 120 # extend the default timeout of 60min since getting a certificate when using a custom domain name can take a while
    environment: '$(environment)'
    strategy:
      runOnce:
        deploy:
          steps:
          - checkout: self # checkout github repository

          - template: steps-set-pipeline-variables.yaml # load the set-pipeline-variables function (used for tags and prefixes)

          # Check if terraform state store exists, and create it if not
          - template: steps-terraform-setup-statestore.yaml
            parameters:
              storageAccountName: '$(terraformStorageAccount)'
              resourceGroupName: '$(terraformResourceGroup)'

          # Global Resources terraform init
          - template: steps-terraform-init.yaml # Initialize Terraform
            parameters:
              terraformStorageAccountName:       '$(terraformStorageAccount)'
              terraformStorageResourceGroupName: '$(terraformResourceGroup)'
              terraformStateFilename:            '$(terraformStateFileGlobal)'
              terraformWorkingDirectory:         '$(workingDirectory)/globalresources'

          - task: AzureCLI@2
            displayName: 'Fetch current Front Door backends'
            inputs:
              azureSubscription: '$(azureServiceConnection)'
              scriptType: pscore
              scriptLocation: inlineScript
              inlineScript: |
                # We need the az CLI Front Door extension
                az extension add --name front-door

                $rgName = "$(prefix)$(globalSuffix)-global-rg"
                $fdName = "$(prefix)$(globalSuffix)-global-fd"

                # check if Front Door exists
                $frontDoor = $(az network front-door list --query "[?name=='$fdName']" -o tsv)

                if($LastExitCode -ne 0)
                {
                    throw "*** Error on checking existing Front Door $fdName"
                }

                $backendPools = @("BackendApis", "StaticStorage")

                if($frontDoor)
                {
                  foreach($pool in $backendPools)
                  {
                    $backends = $(az network front-door backend-pool backend list `
                                    --front-door-name $fdName `
                                    --pool-name $pool -g $rgName `
                                    --query "[].{address:address,weight:weight,enabled:enabledState}")

                    if($LastExitCode -ne 0)
                    {
                        throw "*** Error on fetching existing backends from Front Door $fdName for pool $pool"
                    }

                    $jsonBackends = $backends | ConvertFrom-Json -NoEnumerate
                    # Rewrite EnabledState into bool (true/false)
                    foreach($backend in $jsonBackends)
                    {
                      if($backend.enabled -eq "Enabled")
                      {
                        $backend.enabled = "true"
                      }
                      else
                      {
                        $backend.enabled = "false"
                      }
                    }

                    $flatJsonApis = $jsonBackends | ConvertTo-Json -Compress -Depth 100 -AsArray
                    echo "*** Current backends in pool $($pool): " $flatJsonApis
                    $contentBackends = "-var='backends_$pool=$flatJsonApis'"

                    echo "##vso[task.setvariable variable=tfParameterFrontDoor$pool]$contentBackends"
                  }
                }
                else
                {
                  echo "*** Front Door $fdName does not exist. Using dummy backends from TF variable defaults"

                  # Writing empty ADO variables for each backend pool
                  foreach($pool in $backendPools)
                  {
                    echo "##vso[task.setvariable variable=tfParameterFrontDoor$pool]"
                  }
                }

          # Global Resources deployment
          - template: steps-terraform-apply.yaml # terraform validate, plan and apply for global resources
            parameters:
              jobName:                    'GlobalInfra'
              terraformWorkingDirectory:  '$(workingDirectory)/globalresources'
              customPrefix:               '$(prefix)'      # custom resource prefix
              customSuffix:               '$(globalSuffix)'
              customAttributes:           '-var=branch="$(sourceBranch)"
                                          -var=queued_by="$(Build.QueuedBy)"
                                          -var=contact_email="$(contactEmail)"
                                          -var=''stamps=$(stampLocations)''
                                          $(tfParameterFrontDoorBackendApis)
                                          $(tfParameterFrontDoorStaticStorage)
                                          $(terraformAdditionalParametersCustomDomains)'

- stage: deployreleaseinfrastructure
  displayName: 'Deploy Release Unit Infrastructure' # Deploy Release Unit Azure Infrastructure
  dependsOn: deployglobalinfrastructure
  jobs:
  - job: deployterraform
    displayName: 'Deploy Terraform Release Unit Resources'
    timeoutInMinutes: 120 # extend the default timeout of 60min since getting a certificate when using a custom domain name can take a while
    steps:
    - checkout: self # checkout github repository
    - download: current # download pipeline artifacts

    - template: steps-set-pipeline-variables.yaml # load the set-pipeline-variables function (used for tags and prefixes)

    - template: steps-parse-terraform-output.yaml
      parameters:
        workingDirectory: '$(Pipeline.Workspace)/terraformOutputGlobalInfra'  # Global infra deploy output directory

    # Release Unit Resources terraform init
    - template: steps-terraform-init.yaml
      parameters:
        terraformStorageAccountName:        '$(terraformStorageAccount)'
        terraformStorageResourceGroupName:  '$(terraformResourceGroup)'
        terraformStateFilename:             '$(terraformStateFileReleaseUnit)'
        terraformWorkingDirectory:          '$(workingDirectory)/releaseunit'

    # Pick a VNet from the list of pre-provided VNets or create news one if needed
    - template: steps-get-or-create-vnet.yaml
      parameters:
        prefix: $(prefix)
        suffix: $(customSuffix)

    # Release Unit Resources deployment
    - template: steps-terraform-apply.yaml # terraform validate, plan and apply for global resources
      parameters:
        jobName:                    'ReleaseUnitInfra'
        terraformWorkingDirectory:  '$(workingDirectory)/releaseunit'
        customPrefix:               '$(prefix)'
        customSuffix:               '$(customSuffix)'
        customAttributes:           '-var=branch="$(sourceBranch)"
                                    -var=queued_by="$(Build.QueuedBy)"
                                    -var=contact_email="$(contactEmail)"
                                    -var=''stamps=$(stampLocations)''
                                    -var=''vnet_resource_ids=$(tfParameterVnetResourceIds)''
                                    -var=kubernetes_version="$(kubernetesVersion)"
                                    -var=global_resource_group_name="$(global_resource_group_name)"
                                    -var=monitoring_resource_group_name="$(monitoring_resource_group_name)"
                                    -var=cosmosdb_account_name="$(cosmosdb_account_name)"
                                    -var=cosmosdb_database_name="$(cosmosdb_database_name)"
                                    -var=acr_name="$(acr_name)"
                                    -var=frontdoor_resource_id="$(frontdoor_resource_id)"
                                    -var=frontdoor_name="$(frontdoor_name)"
                                    -var=frontdoor_id_header="$(frontdoor_id_header)"
                                    -var=global_storage_account_name="$(global_storage_account_name)"
                                    -var=azure_monitor_action_group_resource_id="$(azure_monitor_action_group_resource_id)"'

- stage: deployconfiguration
  displayName: 'Deploy Configuration' # Apply configuration to Azure Infrastructure
  dependsOn: deployreleaseinfrastructure
  jobs:
  - template: jobs-configuration.yaml

- stage: testcode
  displayName: 'Test Application Code'
  dependsOn: [] # can run in parallel to the global infra deployment at the very start
  jobs:
  - template: jobs-code-tests.yaml
    parameters:
      jobName:          'CodeTests'
      workingDirectory: 'src/app'

- stage: buildapplication
  displayName: 'Build Application Code'
  dependsOn:
   - testcode
   - deployglobalinfrastructure # requires the global infra to be deployed which contains the Container Registry
  jobs: # using jobs so they each runs in parallel

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'catalogservice' # unique pipeline job name
      containerImageName:       '$(catalogserviceImageName)'  # container image name for CatalogService
      containerImageDockerFile: '$(catalogserviceDockerfile)' # dockerfile used to build the CatalogService

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'backgroundprocessor' # unique pipeline job name
      containerImageName:       '$(backgroundprocessorImageName)'   # container image name for BackgroundProcessor
      containerImageDockerFile: '$(backgroundprocessorDockerfile)'  # dockerfile used to build the BackgroundProcessor

  - template: jobs-container-build.yaml
    parameters:
      jobName:                  'healthservice' # unique pipeline job name
      containerImageName:       '$(healthserviceImageName)'  # container image name for healthservice
      containerImageDockerFile: '$(healthserviceDockerfile)' # dockerfile used to build the healthservice

  - template: jobs-ui-app-build.yaml
    parameters:
      jobName:          'buildui'
      workingDirectory: 'src/app/AlwaysOn.UI'

- stage: deployworkload # Deploy workload to previously created infrastructure
  displayName: 'Deploy Workload'
  dependsOn:
  - deployconfiguration
  - testcode
  - buildapplication
  jobs:
  - template: jobs-workload-deploy.yaml

- stage: importSampleData # Import sample data
  displayName: 'Import sample data'
  dependsOn: deployworkload
  jobs:
  - template: jobs-init-sampledata.yaml

- stage: testingOnlyStampEndpoints # smoke-testing the stamp endpoints
  displayName: 'Testing Stamp Endpoints'
  dependsOn: importSampleData
  jobs:
  - template: jobs-smoke-testing.yaml
    parameters:
      testStampEndpoints: true
      testGlobalEndpoint: false

- ${{ each step in parameters.trafficSwitchSteps }}: # based on the list parameter trafficSwitchSteps this step will be repeated n number of times
  - template: stages-configure-frontdoor.yaml
    parameters:
      trafficWeightNewBackends: ${{ step }}

- stage: testingGlobalEndpoints # smoke-testing global endpoint only after the switchover has happened
  displayName: 'Testing Global Endpoint'
  jobs:
  - template: jobs-smoke-testing.yaml
    parameters:
      testStampEndpoints: false
      testGlobalEndpoint: true

- ${{ if eq(parameters.destroyOldEnvironment, 'true') }}: # Only for E2E the user could have manually chosen not to destroy the environment
  - stage: destroyOldInfrastructure                # In E2E this will destroy the infrastructure that was deployed from the same branch. For int/prod, this will fetch the previous release infra and destroy that
    displayName: 'Destroy Infrastructure'
    jobs:
    - deployment: 'destroyOldReleaseStampsJob' # Using a deployment job so that we can have manual approves, which are configured on the environment specificed below
      displayName: 'Destroy Old Release Unit Deployment'
      environment: '$(environment)'
      strategy:
        runOnce:
          deploy:
            steps:

            - checkout: self # checkout github repository

            - template: steps-set-pipeline-variables.yaml # load set-pipeline-variables function

            - template: steps-buildagent-prerequisites.yaml # Install tools like kubectl

            - ${{ if ne(parameters.environment, 'e2e') }}: # Only in int/prod
              - task: AzureCLI@2
                displayName: 'Fetch previous release prefix through disabled Front Door backends'
                inputs:
                  azureSubscription: '$(azureServiceConnection)'
                  scriptType: pscore
                  scriptLocation: inlineScript
                  inlineScript: |
                    # We need the az CLI Front Door extension
                    az extension add --name front-door

                    $globalInfraDeployOutput = Get-ChildItem $(Pipeline.Workspace)/terraformOutputGlobalInfra/*.json | Get-Content | ConvertFrom-JSON

                    $rgName = $globalInfraDeployOutput.global_resource_group_name.value
                    $fdName = $globalInfraDeployOutput.frontdoor_name.value

                    # Fetch disabled backends from the BackendApis pool. We only fetch the first one, assuming it represents all the stamps of the previous release unit
                    $disabledBackendAddress = $(az network front-door backend-pool backend list `
                                      --front-door-name $fdName `
                                      --pool-name BackendApis `
                                      --resource-group $rgName `
                                      --query "[?enabledState=='Disabled'].{address:address}[0]" -o tsv)

                    if($LastExitCode -ne 0)
                    {
                        throw "*** Error on fetching existing backends from Front Door $fdName for pool 'BackendApis'. Make sure the backend pool exists!"
                    }

                    $prefix = "$(prefix)"

                    # Only valid if we found any disabled backend (=an old release unit)
                    if($disabledBackendAddress)
                    {
                      echo "*** Found disabled backend $disabledBackendAddress"

                      # Lookup the Public IP resource for this FQDN and fetch the Prefix tag from it
                      $prefixSuffix = az network public-ip list --query "[?dnsSettings.fqdn == '$disabledBackendAddress'].{prefix:tags.Prefix}" -o tsv

                      if(-not $prefixSuffix)
                      {
                        throw "*** No Public IP found (or not Prefix tag) for FQDN $disabledBackendAddress"
                      }

                      echo "*** Found prefix-suffix $prefixSuffix"

                      $suffix = $prefixSuffix -creplace "$prefix","" # get suffix by removing the prefix from the prefixSuffix
                    }

                    if((-not $disabledBackendAddress) -or (-not $suffix))
                    {
                      # This can happen on the very first run of the INT or PROD pipeline. We'll set the prefix to some dummy. Terraform destroy will be happy but has nothing to really destroy
                      Write-Warning "*** No disabled backends found or prefix empty. Nothing to destroy."

                      $suffix = "SUFF" # using some dummy value
                    }

                    # set pipeline variables
                    echo "##vso[task.setvariable variable=oldReleasePrefix]$prefix"
                    echo "##vso[task.setvariable variable=oldReleaseSuffix]$suffix"

            - ${{ if eq(parameters.environment, 'e2e') }}: # Special case for E2E only
              - task: PowerShell@2
                displayName: '(E2E-only) Set oldRelease Prefix and Suffix to prefix-customSuffix'
                inputs:
                  targetType: inline
                  script: |
                    # Setting oldReleasePrefix=prefix-customSuffix means that we target the same release unit that was deployed earlier by this very pipeline
                    echo "*** Setting pipeline variables oldReleasePrefix/Suffix = $(prefix) $(customSuffix)"

                    echo "##vso[task.setvariable variable=oldReleasePrefix]$(prefix)"
                    echo "##vso[task.setvariable variable=oldReleaseSuffix]$(customSuffix)"

            - template: steps-parse-terraform-output.yaml
              parameters:
                workingDirectory: '$(Pipeline.Workspace)/terraformOutputGlobalInfra'  # Global infra deploy output directory


            # Delete all deployments in the workload namespace. This will make sure the application is not running anymore before we destroy the infrastructure in the next step.
            # This prevents side effects in the logging in which errors might show up which are only related to the destructions of the infra
            - task: AzureCLI@2
              displayName: 'Delete application deployments on AKS prior to destroy'
              inputs:
                azureSubscription: $(azureServiceConnection)
                scriptType: pscore
                scriptLocation: inlineScript
                inlineScript: |

                  # Find AKS clusters with the prefix $(oldReleasePrefix)
                  $aksClusters = az resource list --tag prefix="$(oldReleasePrefix)$(oldReleaseSuffix)" --query "[?type == 'Microsoft.ContainerService/managedClusters']" | ConvertFrom-Json

                  echo "*** Found $($aksClusters.Count) AKS cluster(s) for prefix-suffix $(oldReleasePrefix)$(oldReleaseSuffix)"

                  # loop through all clusters
                  foreach($cluster in $aksClusters) {

                    $aksClusterName = $cluster.name
                    $aksClusterResourceGroup = $cluster.resourceGroup

                    echo "*** Load credentials for AKS Cluster $aksClusterName in $aksClusterResourceGroup"
                    az aks get-credentials --name $aksClusterName --resource-group $aksClusterResourceGroup --overwrite-existing

                    echo "*** Deleting all deployments in namespace $(workloadNamespace)"
                    kubectl delete --all deployments --namespace=$(workloadNamespace)
                  }

            # Pick a VNet from the list of pre-provided VNets or create news one if needed
            - template: steps-get-or-create-vnet.yaml
              parameters:
                prefix: $(oldReleasePrefix)
                suffix: $(oldReleaseSuffix)

            # Initialize Terraform for destroy
            - template: steps-terraform-destroy.yaml
              parameters:
                terraformStorageAccountName:       '$(terraformStorageAccount)'
                terraformStorageResourceGroupName: '$(terraformResourceGroup)'
                terraformStateFilename:            'terraform-$(oldReleasePrefix)$(oldReleaseSuffix).state'
                terraformWorkingDirectory:         '$(workingDirectory)/releaseunit'
                customAttributes:        '-var=prefix="$(oldReleasePrefix)"
                                          -var=suffix="$(oldReleaseSuffix)"
                                          -var=branch="$(sourceBranch)"
                                          -var=queued_by="$(Build.QueuedBy)"
                                          -var=contact_email="$(contactEmail)"
                                          -var=''stamps=$(stampLocations)''
                                          -var=''vnet_resource_ids=$(tfParameterVnetResourceIds)''
                                          -var=kubernetes_version="$(kubernetesVersion)"
                                          -var=global_resource_group_name="$(global_resource_group_name)"
                                          -var=monitoring_resource_group_name="$(monitoring_resource_group_name)"
                                          -var=cosmosdb_account_name="$(cosmosdb_account_name)"
                                          -var=cosmosdb_database_name="$(cosmosdb_database_name)"
                                          -var=acr_name="$(acr_name)"
                                          -var=frontdoor_resource_id="$(frontdoor_resource_id)"
                                          -var=frontdoor_name="$(frontdoor_name)"
                                          -var=frontdoor_id_header="$(frontdoor_id_header)"
                                          -var=global_storage_account_name="$(global_storage_account_name)"
                                          -var=azure_monitor_action_group_resource_id="$(azure_monitor_action_group_resource_id)"'

            # We need to clean up the VNets that were either pre-provided or temporarily created
            # In case of pre-provided VNets: We need to remove the earmark tag so that it appears available again for future releases
            # In case of temporarily created VNets: We delete the entire resource group which holds all the - now empty - VNets which have been created just for this release
            - task: AzureCLI@2
              displayName: 'Clean up VNets'
              inputs:
                azureSubscription: '$(azureServiceConnection)'
                scriptType: pscore
                scriptLocation: inlineScript
                inlineScript: |

                  $stampLocations = '$(stampLocations)' | ConvertFrom-Json -NoEnumerate

                  $vnetFile = "$(System.DefaultWorkingDirectory)/.ado/pipelines/config/vnets-$(environment).json"

                  if(Test-Path $vnetFile)
                  {
                    echo "*** Using provided VNets from file $vnetFile"

                    $earmarkTagName = "AlwaysOnVnetUsedBy"

                    foreach($location in $stampLocations)
                    {
                      echo "*** Finding VNet for region $location"

                      $expectedTagValue = "$(oldReleasePrefix)$(oldReleaseSuffix)-$location"

                      # Fetch the VNet which was earmaked for this release-location
                      $vnet = az network vnet list --query "[?tags.$earmarkTagName == '$expectedTagValue']" | ConvertFrom-Json

                      if($vnet)
                      {
                        echo "*** VNet $($vnet.name) was used by this release. Clearing tag $earmarkTagName"
                        az tag update --operation delete --resource-id $vnet.id --tags $earmarkTagName
                      }
                      else
                      {
                        echo "*** WARNING - no VNet found with tag $earmarkTagName = $expectedTagValue"
                      }
                    }
                  }
                  else
                  {
                    echo "*** No pre-provided VNets for environment $(environment). Assuming temporarily created VNets which will now be deleted..."
                    $rgName = "$(oldReleasePrefix)$(oldReleaseSuffix)-networks-rg"

                    echo "*** Check if Resource Group $rgName exists"
                    $checkRg = az group exists --name $rgName | ConvertFrom-Json
                    if (!$checkRg) {
                      echo "*** Resource Group $rgName does not exist (anymore). Skipping task"
                    }
                    else
                    {
                      echo "*** Deleting resource group $rgName which contains the VNet(s) for this environment"
                      az group delete -g $rgName --yes
                    }
                  }

            # Remove disabled backends from Front Door and reset weight on current ones to 50. (Not required for E2E since we destroy E2E Front Door anyway below)
            - ${{ if ne(parameters.environment, 'e2e') }}:
              - template: steps-frontdoor-traffic-switch.yaml
                parameters:
                  trafficWeightNewBackends: 50
                  removeDisabledBackends: true

    - ${{ if eq(parameters.environment, 'e2e') }}: # Only happens in E2E
      - deployment: 'destroyE2EGlobalResourcesJob'  # Destroy globally shared resources for this E2E env
        displayName: 'Destroy E2E Global Resources'
        environment: '$(environment)'
        dependsOn: 'destroyOldReleaseStampsJob'
        strategy:
          runOnce:
            deploy:
              steps:

              - checkout: self # checkout github repository

              - download: current # download pipeline artifacts

              - template: steps-set-pipeline-variables.yaml # load set-pipeline-variables function

              # Initialize Terraform for destroy
              - template: steps-terraform-destroy.yaml
                parameters:
                  terraformStorageAccountName:        '$(terraformStorageAccount)'
                  terraformStorageResourceGroupName:  '$(terraformResourceGroup)'
                  terraformStateFilename:             '$(terraformStateFileGlobal)'
                  terraformWorkingDirectory:          '$(workingDirectory)/globalresources'
                  customAttributes:           '-var=prefix="$(prefix)"
                                               -var=environment="${{ parameters.environment }}"
                                               -var=suffix="$(globalSuffix)"
                                               -var=''stamps=$(stampLocations)''
                                               $(terraformAdditionalParametersCustomDomains)'
